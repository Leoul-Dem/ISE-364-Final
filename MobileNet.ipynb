{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f452946c",
      "metadata": {
        "id": "f452946c"
      },
      "source": [
        "# MobileNet Fine-Tuning on Multiple Datasets  \n",
        "### On-Device AI: Efficient CNNs for Real-Time Object Recognition  \n",
        "**Team Members:** Sanchita, Simran, Leoul, Sandeep  \n",
        "**Role:** Sandeep (MobileNet Lead)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36a8ffc4",
      "metadata": {
        "id": "36a8ffc4"
      },
      "source": [
        "**Import usual libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8187974",
      "metadata": {
        "id": "f8187974"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
        "import os\n",
        "import time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5e8d56",
      "metadata": {
        "id": "1e5e8d56"
      },
      "source": [
        "**2. CIFAR-100 Data Loaders.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fce7b21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fce7b21",
        "outputId": "8373f3da-36ef-4007-cb77-c2d98ac69f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Train: 50000, Test: 10000, Classes: 100\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --- Transforms ---\n",
        "# Using ImageNet normalization because we're using an ImageNet-pretrained MobileNet\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# --- Datasets & loaders (CIFAR-100) ---\n",
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_tfms)\n",
        "testset  = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_tfms)\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 2\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
        "testloader  = DataLoader(testset,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "classes = trainset.classes  # list of 100 class names\n",
        "print(f\"Train: {len(trainset)}, Test: {len(testset)}, Classes: {len(classes)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782c2308",
      "metadata": {
        "id": "782c2308"
      },
      "source": [
        "**3. Build MobileNet (pretrained) for 100 classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad5784c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad5784c",
        "outputId": "2f6c7844-d3ea-41c3-87c5-76c29b83e8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=576, out_features=1024, bias=True)\n",
            "  (1): Hardswish()\n",
            "  (2): Dropout(p=0.2, inplace=True)\n",
            "  (3): Linear(in_features=1024, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load ImageNet-pretrained MobileNetV3-Small\n",
        "weights = MobileNet_V3_Small_Weights.IMAGENET1K_V1\n",
        "model = mobilenet_v3_small(weights=weights)\n",
        "\n",
        "# Replace classifier head for 100 classes\n",
        "in_feats = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_feats, 100)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model.classifier)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e95314",
      "metadata": {
        "id": "27e95314"
      },
      "source": [
        "**4. Loss & optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9c9980",
      "metadata": {
        "id": "0c9c9980"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
        "# Optional but helpful:\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21057b01",
      "metadata": {
        "id": "21057b01"
      },
      "source": [
        "**5. Training loops**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e9aae29",
      "metadata": {
        "id": "0e9aae29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d8c74e-b2a0-4e37-de96-e8cbbb33e2e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training…\n",
            "[Epoch 1, End] loss: 1.5228\n",
            "[Epoch 2, End] loss: 0.9427\n",
            "[Epoch 3, End] loss: 0.8366\n",
            "[Epoch 4, End] loss: 0.8125\n",
            "[Epoch 5, End] loss: 0.8080\n",
            "[Epoch 6, End] loss: 0.8071\n",
            "[Epoch 7, End] loss: 0.8215\n",
            "[Epoch 8, End] loss: 0.8506\n",
            "[Epoch 9, End] loss: 0.8685\n",
            "[Epoch 10, End] loss: 0.8907\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "def train(model, trainloader, epochs=20, print_every=1000):\n",
        "    model.train()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(trainloader, start=1):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % print_every == 0:\n",
        "                print(f\"[Epoch {epoch}, Batch {i}] loss: {running_loss/print_every:.4f}\")\n",
        "                running_loss = 0.0\n",
        "        if 'scheduler' in globals() and scheduler is not None:\n",
        "            scheduler.step()\n",
        "        # epoch summary\n",
        "        if running_loss > 0:\n",
        "            print(f\"[Epoch {epoch}, End] loss: {running_loss/(len(trainloader)%print_every):.4f}\")\n",
        "\n",
        "print(\"Starting training…\")\n",
        "train(model, trainloader, epochs=10, print_every=500)  # adjust epochs as needed\n",
        "print(\"Finished Training\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d977540f",
      "metadata": {
        "id": "d977540f"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Accurancy\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy on CIFAR-100: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdLEoDrAMN7f",
        "outputId": "cc40b343-6b20-416d-b616-36c1205e6766"
      },
      "id": "JdLEoDrAMN7f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy on CIFAR-100: 46.48%\n",
            "\n",
            "Test Accuracy on CIFAR-100: 46.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Size**"
      ],
      "metadata": {
        "id": "4np0yMFdMSTX"
      },
      "id": "4np0yMFdMSTX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Size\n",
        "save_path = \"mobilenet_cifar100.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "size_mb = os.path.getsize(save_path) / (1024 * 1024)\n",
        "print(f\"Model Size: {size_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XaelmFxM5uH",
        "outputId": "5998a73d-e3fa-4692-a78a-454d967f9528"
      },
      "id": "5XaelmFxM5uH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 6.31 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference Speed (ms/image + FPS)**"
      ],
      "metadata": {
        "id": "END3xdFjMXXS"
      },
      "id": "END3xdFjMXXS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference Speed (ms/image + FPS)\n",
        "\n",
        "model.eval()\n",
        "images, _ = next(iter(testloader))\n",
        "images = images.to(device)\n",
        "\n",
        "# warmup\n",
        "for _ in range(10):\n",
        "    _ = model(images)\n",
        "\n",
        "# measure\n",
        "start = time.time()\n",
        "for _ in range(50):\n",
        "    _ = model(images)\n",
        "end = time.time()\n",
        "\n",
        "avg_batch_time = (end - start) / 50\n",
        "ms_per_image = (avg_batch_time / images.size(0)) * 1000\n",
        "fps = images.size(0) / avg_batch_time\n",
        "\n",
        "print(f\"Inference Time Per Image: {ms_per_image:.3f} ms\")\n",
        "print(f\"FPS: {fps:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTDWaNcaND_b",
        "outputId": "2f122c50-8ee7-4dbf-d4f0-d456abc2e645"
      },
      "id": "LTDWaNcaND_b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Per Image: 0.232 ms\n",
            "FPS: 4303.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== Performance Summary (MobileNet + CIFAR-100) =====\")\n",
        "print(f\"Accuracy:           {accuracy:.2f}%\")\n",
        "print(f\"Model Size:         {size_mb:.2f} MB\")\n",
        "print(f\"Inference (ms/img): {ms_per_image:.3f} ms\")\n",
        "print(f\"FPS:                {fps:.2f}\")\n",
        "print(f\"Training Time:      30 min\")\n",
        "print(\"========================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJxWIAPYNRjp",
        "outputId": "8f7fab71-0868-4a5a-e68f-a4383d11dfcb"
      },
      "id": "qJxWIAPYNRjp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Performance Summary (MobileNet + CIFAR-100) =====\n",
            "Accuracy:           46.48%\n",
            "Model Size:         6.31 MB\n",
            "Inference (ms/img): 0.232 ms\n",
            "FPS:                4303.85\n",
            "Training Time:      30 min\n",
            "========================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Foods101 Dataset\n"
      ],
      "metadata": {
        "id": "51Na8sYmF_GI"
      },
      "id": "51Na8sYmF_GI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcpanfN-GMK_"
      },
      "source": [
        "**Import usual libraries.**"
      ],
      "id": "OcpanfN-GMK_"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import Food101\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "fad7-_j3GN4h"
      },
      "id": "fad7-_j3GN4h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Food-100 Data Loaders.**"
      ],
      "metadata": {
        "id": "upyfG3X_GdL7"
      },
      "id": "upyfG3X_GdL7"
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "trainset = Food101(root='./data', split='train', transform=train_transform, download=True)\n",
        "testset = Food101(root='./data', split='test', transform=test_transform, download=True)\n",
        "\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgUDBB8UGdmx",
        "outputId": "1d8accf8-2608-4e72-eb07-8ac236d7ba65"
      },
      "id": "kgUDBB8UGdmx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.00G/5.00G [04:19<00:00, 19.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define MobileNetV3-Small for 101 Classes**"
      ],
      "metadata": {
        "id": "2dyThhFJHCfN"
      },
      "id": "2dyThhFJHCfN"
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.mobilenet_v3_small(weights=None)\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 101)  # 101 classes\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "s9gKobP_HE_q"
      },
      "id": "s9gKobP_HE_q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss + Optimizer**"
      ],
      "metadata": {
        "id": "aIsn0zMSHjTs"
      },
      "id": "aIsn0zMSHjTs"
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "QbKDP34aHnYG"
      },
      "id": "QbKDP34aHnYG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Function**"
      ],
      "metadata": {
        "id": "Cm21q27RHsbB"
      },
      "id": "Cm21q27RHsbB"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(model, trainloader, epochs=10, print_every=500):\n",
        "    model.train()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(trainloader, start=1):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % print_every == 0:\n",
        "                print(f\"[Epoch {epoch}, Batch {i}] loss: {running_loss/print_every:.4f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "# ---------- TRAIN + TIME ----------\n",
        "start_time = time.time()\n",
        "\n",
        "train(model, trainloader, epochs=10, print_every=500)\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = (end_time - start_time) / 60\n",
        "print(f\"Training Time: {total_training_time:.2f} min\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppK8a5_QHvue",
        "outputId": "c9e5494f-cee1-43ea-910b-5a25041ec609"
      },
      "id": "ppK8a5_QHvue",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 500] loss: 4.4002\n",
            "[Epoch 1, Batch 1000] loss: 4.1209\n",
            "[Epoch 1, Batch 1500] loss: 3.9350\n",
            "[Epoch 1, Batch 2000] loss: 3.7895\n",
            "[Epoch 2, Batch 500] loss: 3.5932\n",
            "[Epoch 2, Batch 1000] loss: 3.5045\n",
            "[Epoch 2, Batch 1500] loss: 3.4155\n",
            "[Epoch 2, Batch 2000] loss: 3.3418\n",
            "[Epoch 3, Batch 500] loss: 3.1668\n",
            "[Epoch 3, Batch 1000] loss: 3.1312\n",
            "[Epoch 3, Batch 1500] loss: 3.0698\n",
            "[Epoch 3, Batch 2000] loss: 2.9971\n",
            "[Epoch 4, Batch 500] loss: 2.8515\n",
            "[Epoch 4, Batch 1000] loss: 2.8173\n",
            "[Epoch 4, Batch 1500] loss: 2.7640\n",
            "[Epoch 4, Batch 2000] loss: 2.7386\n",
            "[Epoch 5, Batch 500] loss: 2.6009\n",
            "[Epoch 5, Batch 1000] loss: 2.5833\n",
            "[Epoch 5, Batch 1500] loss: 2.5403\n",
            "[Epoch 5, Batch 2000] loss: 2.5329\n",
            "[Epoch 6, Batch 500] loss: 2.4051\n",
            "[Epoch 6, Batch 1000] loss: 2.3892\n",
            "[Epoch 6, Batch 1500] loss: 2.3589\n",
            "[Epoch 6, Batch 2000] loss: 2.3291\n",
            "[Epoch 7, Batch 500] loss: 2.2211\n",
            "[Epoch 7, Batch 1000] loss: 2.2072\n",
            "[Epoch 7, Batch 1500] loss: 2.2032\n",
            "[Epoch 7, Batch 2000] loss: 2.1928\n",
            "[Epoch 8, Batch 500] loss: 2.0641\n",
            "[Epoch 8, Batch 1000] loss: 2.1051\n",
            "[Epoch 8, Batch 1500] loss: 2.0848\n",
            "[Epoch 8, Batch 2000] loss: 2.0670\n",
            "[Epoch 9, Batch 500] loss: 1.9615\n",
            "[Epoch 9, Batch 1000] loss: 1.9650\n",
            "[Epoch 9, Batch 1500] loss: 1.9785\n",
            "[Epoch 9, Batch 2000] loss: 1.9619\n",
            "[Epoch 10, Batch 500] loss: 1.8611\n",
            "[Epoch 10, Batch 1000] loss: 1.8486\n",
            "[Epoch 10, Batch 1500] loss: 1.8610\n",
            "[Epoch 10, Batch 2000] loss: 1.8856\n",
            "Finished Training\n",
            "Training Time: 63.18 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "VR5mvwfWKa8y"
      },
      "id": "VR5mvwfWKa8y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Accuracy on Food101\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy on Food101: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "6nmqlwfBKqZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a104951-af49-43c3-83cf-3648ce2cd3f5"
      },
      "id": "6nmqlwfBKqZS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy on Food101: 54.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Measure Model Size**"
      ],
      "metadata": {
        "id": "lpjTtJvBKrVc"
      },
      "id": "lpjTtJvBKrVc"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "torch.save(model.state_dict(), \"temp_model.pth\")\n",
        "size_mb = os.path.getsize(\"temp_model.pth\") / (1024 * 1024)\n",
        "os.remove(\"temp_model.pth\")\n",
        "\n",
        "print(f\"Model Size: {size_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "id": "gupVNzSyKsqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7142493c-2493-4b64-e4ff-3c3dd4518172"
      },
      "id": "gupVNzSyKsqV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 6.31 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference Time (ms per image & FPS)**"
      ],
      "metadata": {
        "id": "As7j9BKuKx7W"
      },
      "id": "As7j9BKuKx7W"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_inference_speed(model, device, num_runs=200):\n",
        "    model.eval()\n",
        "\n",
        "    data_iter = iter(testloader)\n",
        "    images, _ = next(data_iter)\n",
        "    images = images.to(device)\n",
        "\n",
        "    # warm-up\n",
        "    for _ in range(20):\n",
        "        _ = model(images)\n",
        "\n",
        "    # timing\n",
        "    start = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        _ = model(images)\n",
        "    end = time.time()\n",
        "\n",
        "    total_time = end - start\n",
        "    ms_per_image = (total_time / (num_runs * images.size(0))) * 1000\n",
        "    fps = 1000 / ms_per_image\n",
        "\n",
        "    print(f\"Inference Time Per Image: {ms_per_image:.3f} ms\")\n",
        "    print(f\"FPS: {fps:.2f}\")\n",
        "\n",
        "    return ms_per_image, fps\n",
        "\n",
        "ms_per_image, fps = measure_inference_speed(model, device)\n"
      ],
      "metadata": {
        "id": "oub17jjzKyPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d586e3-4dcf-4ac0-a019-ee8e71b02e53"
      },
      "id": "oub17jjzKyPZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Per Image: 0.330 ms\n",
            "FPS: 3028.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Performance Summary**"
      ],
      "metadata": {
        "id": "v90ehW2OMNsh"
      },
      "id": "v90ehW2OMNsh"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== Performance Summary (MobileNet + Food101) =====\")\n",
        "print(f\"Accuracy:           {accuracy:.2f}%\")\n",
        "print(f\"Model Size:         {size_mb:.2f} MB\")\n",
        "print(f\"Inference (ms/img): {ms_per_image:.3f} ms\")\n",
        "print(f\"FPS:                {fps:.2f}\")\n",
        "print(f\"Training Time:      {total_training_time:.2f} min\")\n",
        "print(\"=====================================================\\n\")\n"
      ],
      "metadata": {
        "id": "GqMD5MR1K1dX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8012a9f2-f41f-4d0b-c2ac-1a9999c41d0f"
      },
      "id": "GqMD5MR1K1dX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Performance Summary (MobileNet + Food101) =====\n",
            "Accuracy:           54.34%\n",
            "Model Size:         6.31 MB\n",
            "Inference (ms/img): 0.330 ms\n",
            "FPS:                3028.05\n",
            "Training Time:      63.18 min\n",
            "=====================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "41DeT3IFICEG"
      },
      "id": "41DeT3IFICEG"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "jd7MnYzrIBUw"
      },
      "id": "jd7MnYzrIBUw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # convert 1 channel → 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "i39ky4L9Kcfw"
      },
      "id": "i39ky4L9Kcfw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2JAl0KQKfu1",
        "outputId": "d9174e8f-066e-479f-a995-0a76b2a6758f"
      },
      "id": "S2JAl0KQKfu1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 205kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.85MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
        "testloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "print(\"Train batches:\", len(trainloader))\n",
        "print(\"Test batches:\", len(testloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RcsxjVuKjte",
        "outputId": "f05bb6fa-b6ed-43f6-84d3-3f5f07999491"
      },
      "id": "-RcsxjVuKjte",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 938\n",
            "Test batches: 157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "model = models.mobilenet_v3_small(pretrained=True)\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 10)\n",
        "model = model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PEZraMAnKrd8"
      },
      "id": "PEZraMAnKrd8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "id5BhR-SK6s9"
      },
      "id": "id5BhR-SK6s9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train_fmnist(model, trainloader, epochs=10, print_every=500):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(trainloader, start=1):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if i % print_every == 0:\n",
        "                print(f\"[Epoch {epoch}, Batch {i}] loss: {running_loss/print_every:.4f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # epoch end message\n",
        "        print(f\"[Epoch {epoch}, End] loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    return True\n",
        "\n",
        "\n",
        "# ======== TRAIN + TIME ==========\n",
        "start_time = time.time()\n",
        "\n",
        "train_fmnist(model, trainloader, epochs=10, print_every=500)\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = (end_time - start_time) / 60\n",
        "\n",
        "print(f\"\\nTraining Time: {total_training_time:.2f} min\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V17Gu3bOK9-k",
        "outputId": "bf891626-36c6-4346-c869-22ab282a1d62"
      },
      "id": "V17Gu3bOK9-k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 500] loss: 0.3169\n",
            "[Epoch 1, End] loss: 0.1025\n",
            "[Epoch 2, Batch 500] loss: 0.1806\n",
            "[Epoch 2, End] loss: 0.0859\n",
            "[Epoch 3, Batch 500] loss: 0.1530\n",
            "[Epoch 3, End] loss: 0.0723\n",
            "[Epoch 4, Batch 500] loss: 0.1316\n",
            "[Epoch 4, End] loss: 0.0642\n",
            "[Epoch 5, Batch 500] loss: 0.1188\n",
            "[Epoch 5, End] loss: 0.0578\n",
            "[Epoch 6, Batch 500] loss: 0.1011\n",
            "[Epoch 6, End] loss: 0.0529\n",
            "[Epoch 7, Batch 500] loss: 0.0874\n",
            "[Epoch 7, End] loss: 0.0445\n",
            "[Epoch 8, Batch 500] loss: 0.0752\n",
            "[Epoch 8, End] loss: 0.0394\n",
            "[Epoch 9, Batch 500] loss: 0.0629\n",
            "[Epoch 9, End] loss: 0.0367\n",
            "[Epoch 10, Batch 500] loss: 0.0500\n",
            "[Epoch 10, End] loss: 0.0296\n",
            "Finished Training\n",
            "\n",
            "Training Time: 19.43 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy_fmnist = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy on Fashion-MNIST: {accuracy_fmnist:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZihV9WwMLiR4",
        "outputId": "48715a89-02b7-4430-d8a8-5c25bbea45d6"
      },
      "id": "ZihV9WwMLiR4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy on Fashion-MNIST: 93.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "torch.save(model.state_dict(), \"mobilenet_fmnist.pth\")\n",
        "\n",
        "size_mb_fmnist = os.path.getsize(\"mobilenet_fmnist.pth\") / (1024 * 1024)\n",
        "print(f\"Model Size: {size_mb_fmnist:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfQSCQI7LmxR",
        "outputId": "dde0359f-68a7-4450-9e89-175f1fa86be8"
      },
      "id": "GfQSCQI7LmxR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 5.96 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "model.eval()\n",
        "num_images = 200\n",
        "images_seen = 0\n",
        "total_time = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, _ in testloader:\n",
        "        images = images.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "        _ = model(images)\n",
        "        end = time.time()\n",
        "\n",
        "        batch_time = end - start\n",
        "        total_time += batch_time\n",
        "        images_seen += images.size(0)\n",
        "\n",
        "        if images_seen >= num_images:\n",
        "            break\n",
        "\n",
        "ms_per_image_fmnist = (total_time / images_seen) * 1000\n",
        "fps_fmnist = 1 / (ms_per_image_fmnist / 1000)\n",
        "\n",
        "print(f\"\\nInference Time Per Image: {ms_per_image_fmnist:.3f} ms\")\n",
        "print(f\"FPS: {fps_fmnist:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmg_M62mLp6I",
        "outputId": "4236a9d6-cc2b-40c1-b5ca-40d26144728f"
      },
      "id": "dmg_M62mLp6I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inference Time Per Image: 0.439 ms\n",
            "FPS: 2280.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== Performance Summary (MobileNet + Fashion-MNIST) =====\")\n",
        "print(f\"Accuracy:            {accuracy_fmnist:.2f}%\")\n",
        "print(f\"Model Size:          {size_mb_fmnist:.2f} MB\")\n",
        "print(f\"Inference (ms/img):  {ms_per_image_fmnist:.3f} ms\")\n",
        "print(f\"FPS:                 {fps_fmnist:.2f}\")\n",
        "print(f\"Training Time:       {total_training_time:.2f} min\")\n",
        "print(\"============================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dst2rVZOLrgW",
        "outputId": "a1ce4e24-ae1e-4c01-99bd-3d11ef5e45f1"
      },
      "id": "dst2rVZOLrgW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Performance Summary (MobileNet + Fashion-MNIST) =====\n",
            "Accuracy:            93.72%\n",
            "Model Size:          5.96 MB\n",
            "Inference (ms/img):  0.439 ms\n",
            "FPS:                 2280.09\n",
            "Training Time:       19.43 min\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "import time\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN2Uf5lDRk5T",
        "outputId": "07cb9bad-9ccb-4f8c-9d10-bc96c35cdb24"
      },
      "id": "LN2Uf5lDRk5T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======== DATA TRANSFORMS FOR STANFORD CARS =========\n",
        "from torchvision.datasets import QMNIST\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = QMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset  = QMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader  = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"Train batches:\", len(trainloader))\n",
        "print(\"Test batches:\", len(testloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q65cIevUovw",
        "outputId": "22514f7c-e66f-463c-d1ed-780730278268"
      },
      "id": "-Q65cIevUovw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.70M/9.70M [00:00<00:00, 457MB/s]\n",
            "100%|██████████| 463k/463k [00:00<00:00, 69.9MB/s]\n",
            "100%|██████████| 9.74M/9.74M [00:00<00:00, 461MB/s]\n",
            "100%|██████████| 527k/527k [00:00<00:00, 124MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 938\n",
            "Test batches: 938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import mobilenet_v3_small\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 10)  # QMNIST has 10 classes\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv93RjWMUsT5",
        "outputId": "4e0b93c3-13ee-455a-d710-3f4bef0d12cd"
      },
      "id": "Lv93RjWMUsT5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 160MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "F_WzWDzyisRn"
      },
      "id": "F_WzWDzyisRn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train_qmnist(model, trainloader, epochs=10, print_every=500):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(trainloader, start=1):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if i % print_every == 0:\n",
        "                print(f\"[Epoch {epoch}, Batch {i}] loss: {running_loss/print_every:.4f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # epoch end message\n",
        "        print(f\"[Epoch {epoch}, End] loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    return True\n",
        "\n",
        "\n",
        "# ========= TRAIN + TIME =========\n",
        "start_time = time.time()\n",
        "\n",
        "train_qmnist(model, trainloader, epochs=10, print_every=500)\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = (end_time - start_time) / 60\n",
        "\n",
        "print(f\"\\nTraining Time: {total_training_time:.2f} min\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydwYA8AfjL56",
        "outputId": "3b14003e-8397-47f4-906d-2e4c251f5361"
      },
      "id": "ydwYA8AfjL56",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 500] loss: 0.0920\n",
            "[Epoch 1, End] loss: 0.0200\n",
            "[Epoch 2, Batch 500] loss: 0.0311\n",
            "[Epoch 2, End] loss: 0.0142\n",
            "[Epoch 3, Batch 500] loss: 0.0207\n",
            "[Epoch 3, End] loss: 0.0124\n",
            "[Epoch 4, Batch 500] loss: 0.0208\n",
            "[Epoch 4, End] loss: 0.0121\n",
            "[Epoch 5, Batch 500] loss: 0.0181\n",
            "[Epoch 5, End] loss: 0.0098\n",
            "[Epoch 6, Batch 500] loss: 0.0188\n",
            "[Epoch 6, End] loss: 0.0094\n",
            "[Epoch 7, Batch 500] loss: 0.0136\n",
            "[Epoch 7, End] loss: 0.0091\n",
            "[Epoch 8, Batch 500] loss: 0.0151\n",
            "[Epoch 8, End] loss: 0.0088\n",
            "[Epoch 9, Batch 500] loss: 0.0141\n",
            "[Epoch 9, End] loss: 0.0073\n",
            "[Epoch 10, Batch 500] loss: 0.0098\n",
            "[Epoch 10, End] loss: 0.0068\n",
            "Finished Training\n",
            "\n",
            "Training Time: 23.39 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Test Accuracy (QMNIST) =====\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"\\nTest Accuracy on QMNIST: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRiKgLlejbFM",
        "outputId": "271bbc93-4fda-4c31-ccd9-1985278c9d1f"
      },
      "id": "gRiKgLlejbFM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy on QMNIST: 99.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Model Size (QMNIST) =====\n",
        "torch.save(model.state_dict(), \"temp_qmnist_model.pth\")\n",
        "import os\n",
        "\n",
        "size_mb = os.path.getsize(\"temp_qmnist_model.pth\") / (1024 * 1024)\n",
        "print(f\"\\nModel Size: {size_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA1FoakXjcx9",
        "outputId": "0ef35c43-979e-43bd-a3c1-c26e7c6b72a9"
      },
      "id": "qA1FoakXjcx9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Size: 5.96 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Inference Time per Image (QMNIST) =====\n",
        "import time\n",
        "\n",
        "model.eval()\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)  # QMNIST is grayscale (1 channel)\n",
        "\n",
        "# warmup\n",
        "for _ in range(10):\n",
        "    _ = model(dummy_input)\n",
        "\n",
        "# timing\n",
        "start = time.time()\n",
        "runs = 200\n",
        "for _ in range(runs):\n",
        "    _ = model(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "avg_ms = ((end - start) / runs) * 1000\n",
        "fps = 1000 / avg_ms\n",
        "\n",
        "print(f\"\\nInference Time Per Image: {avg_ms:.3f} ms\")\n",
        "print(f\"FPS: {fps:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUBwrfwyj2l_",
        "outputId": "bd040a7e-733f-44ad-854e-37229d1b888e"
      },
      "id": "fUBwrfwyj2l_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inference Time Per Image: 6.282 ms\n",
            "FPS: 159.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== Performance Summary (MobileNet + QMNIST) =====\")\n",
        "print(f\"Accuracy:           {accuracy:.2f}%\")\n",
        "print(f\"Model Size:         {size_mb:.2f} MB\")\n",
        "print(f\"Inference (ms/img): {avg_ms:.3f} ms\")\n",
        "print(f\"FPS:                {fps:.2f}\")\n",
        "print(\"----------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYjHrDjrj4fl",
        "outputId": "9c25f44c-be6f-46ab-f67e-cf159a7d9a7f"
      },
      "id": "mYjHrDjrj4fl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Performance Summary (MobileNet + QMNIST) =====\n",
            "Accuracy:           99.10%\n",
            "Model Size:         5.96 MB\n",
            "Inference (ms/img): 6.282 ms\n",
            "FPS:                159.18\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}